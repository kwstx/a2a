import time
import math
from typing import List, Dict, Any, Tuple
from src.models.impact import ImpactProjection, ImpactVector, ImpactCategory, SurplusPool

class CooperativeSurplusEngine:
    """
    Computes the collective value generated by a cluster of tasks.
    Aggregates impact vectors and applies dependency-aware normalization.
    """
    
    def __init__(self, synergy_multiplier: float = 0.15, dependency_risk_factor: float = 0.05):
        self.synergy_multiplier = synergy_multiplier
        self.dependency_risk_factor = dependency_risk_factor

    def calculate_cluster_surplus(self, cluster_id: str, projections: List[ImpactProjection]) -> SurplusPool:
        """
        Calculates the total predicted cooperative surplus for a list of projections.
        """
        if not projections:
            return SurplusPool(
                cluster_id=cluster_id,
                total_surplus=0.0,
                confidence_interval=(0.0, 0.0),
                aggregated_vectors={},
                task_ids=[]
            )

        task_ids = [p.task_id for p in projections]
        base_surplus = 0.0
        total_variance = 0.0
        
        # Aggregated vectors by category
        aggregated_magnitudes: Dict[str, float] = {}
        
        internal_dependencies = 0
        external_dependencies = 0

        for proj in projections:
            base_surplus += proj.distribution_mean
            
            # Combine variances (std^2)
            total_variance += proj.distribution_std ** 2
            
            # Aggregate vectors (first-order)
            cat_name = proj.target_vector.category.name
            aggregated_magnitudes[cat_name] = aggregated_magnitudes.get(cat_name, 0.0) + proj.target_vector.magnitude
            
            # Check dependencies
            # We look for links within the cluster
            deps = proj.target_vector.causal_dependencies
            for dep in deps:
                if dep in task_ids:
                    internal_dependencies += 1
                else:
                    external_dependencies += 1

        # Synergy density: how interconnected is this cluster?
        num_tasks = len(task_ids)
        max_possible_internal_deps = num_tasks * (num_tasks - 1) if num_tasks > 1 else 1
        synergy_density = internal_dependencies / max_possible_internal_deps

        # Apply dependency-aware normalization
        # Synergy: Internal dependencies increase the total value, weighted by density
        synergy_bonus = 1.0 + (internal_dependencies * self.synergy_multiplier) * (1.0 + synergy_density)
        
        # Risk: External dependencies (uncontrolled) decrease the predicted value
        risk_discount = 1.0 / (1.0 + (external_dependencies * self.dependency_risk_factor))
        
        total_surplus = round(base_surplus * synergy_bonus * risk_discount, 4)
        
        # Aggregate confidence interval
        combined_std = math.sqrt(total_variance)
        # The CI scales with the bonus/discount as well
        scaling_factor = synergy_bonus * risk_discount
        ci_width = 1.96 * combined_std * scaling_factor
        ci_low = round(total_surplus - ci_width, 4)
        ci_high = round(total_surplus + ci_width, 4)

        return SurplusPool(
            cluster_id=cluster_id,
            total_surplus=total_surplus,
            confidence_interval=(ci_low, ci_high),
            aggregated_vectors=aggregated_magnitudes,
            task_ids=task_ids,
            metadata={
                "base_surplus": round(base_surplus, 4),
                "internal_dependencies": internal_dependencies,
                "external_dependencies": external_dependencies,
                "synergy_density": round(synergy_density, 4),
                "synergy_bonus": round(synergy_bonus, 4),
                "risk_discount": round(risk_discount, 4),
                "effective_multiplier": round(scaling_factor, 4)
            }
        )
